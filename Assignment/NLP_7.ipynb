{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uqE7jFaUrzM5",
        "outputId": "3aebc8c5-8d1e-4810-8670-c460ddaf0675"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk) (4.67.1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.util import ngrams\n",
        "from collections import defaultdict, Counter\n",
        "import random\n",
        "import google.generativeai as genai\n",
        "!pip install nltk\n",
        "import nltk\n",
        "\n",
        "# Download the necessary NLTK resource\n",
        "nltk.download('punkt_tab')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "GOOGLE_API_KEY = \"AIzaSyDot0AwvocDlFTE8z0aVSp0dNWNuYzrjec\"\n",
        "genai.configure(api_key=GOOGLE_API_KEY)\n"
      ],
      "metadata": {
        "id": "ajDWucpTvdxL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corpus= \"\"\"In the 2024 national elections, political parties across the country engaged in intense campaigns to win the support of the electorate. The ruling party, led by Prime Minister Aryan Mehta, focused on economic reforms, infrastructure development, and national security. Meanwhile, the opposition, headed by veteran leader Rohan Sharma, emphasized social welfare policies, unemployment reduction, and transparency in governance.\n",
        "\n",
        "Public debates, rallies, and televised interviews played a crucial role in shaping public opinion. The Election Commission introduced new measures to ensure free and fair elections, including stricter monitoring of campaign expenditures and the implementation of electronic voting machines with enhanced security features.\n",
        "\n",
        "During the campaign, the opposition accused the government of corruption and mishandling of public funds, while the ruling party countered by highlighting the rapid GDP growth and foreign investment surge. Opinion polls indicated a neck-and-neck contest, with urban voters leaning towards economic stability and rural voters favoring policies aimed at social justice.\n",
        "\n",
        "As election day approached, political analysts speculated on potential coalition governments in case of a hung parliament. Ultimately, the results revealed a surprising outcomeâ€”despite predictions of a close race, the ruling party secured a comfortable majority, allowing Aryan Mehta to continue his tenure as Prime Minister. The opposition, acknowledging defeat, vowed to strengthen grassroots movements and prepare for the next electoral battle.\n",
        "\n",
        "In the aftermath, discussions on electoral reforms and democratic governance gained momentum, with experts debating the impact of social media, misinformation, and voter behavior on modern democracy.\"\"\"\n",
        "\n",
        "tokens = nltk.word_tokenize(corpus.lower())"
      ],
      "metadata": {
        "id": "TJhBgpqovhbb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ðŸ”¹ Create Bigram and Trigram Models\n",
        "bigrams = list(ngrams(tokens, 2))\n",
        "trigrams = list(ngrams(tokens, 3))\n",
        "\n",
        "# ðŸ”¹ Compute Frequency Distributions\n",
        "bigram_freq = Counter(bigrams)\n",
        "trigram_freq = Counter(trigrams)\n"
      ],
      "metadata": {
        "id": "aNBFAc8fvhjo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_next_word(prev_words, n=3):\n",
        "    \"\"\"Predict the next word based on previous words using an N-Gram model.\"\"\"\n",
        "    prev_words = tuple(prev_words.lower().split()[-(n-1):])  # Get last (n-1) words\n",
        "\n",
        "    # First, try using the trigram model\n",
        "    candidates = {trigram[-1]: count for trigram, count in trigram_freq.items() if trigram[:-1] == prev_words}\n",
        "\n",
        "    # If no trigram candidates, fall back to bigram model\n",
        "    if not candidates:\n",
        "        candidates = {bigram[-1]: count for bigram, count in bigram_freq.items() if bigram[:-1] == prev_words}\n",
        "\n",
        "    # If still no candidates, return a random word\n",
        "    if not candidates:\n",
        "        return random.choice(tokens)\n",
        "\n",
        "    # Choose the most probable next word\n",
        "    next_word = max(candidates, key=candidates.get)\n",
        "    return next_word\n"
      ],
      "metadata": {
        "id": "_5hgXfxPwD9k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def auto_complete_ngram(text, num_suggestions=3):\n",
        "    \"\"\"Generate auto-complete suggestions based on input text.\"\"\"\n",
        "    suggestions = [predict_next_word(text) for _ in range(num_suggestions)]\n",
        "    return list(set(suggestions))  # Return unique suggestions\n"
      ],
      "metadata": {
        "id": "E86iL5EMwEAr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def auto_complete_gemini(text):\n",
        "    \"\"\"Generate auto-complete suggestions using Gemini API.\"\"\"\n",
        "    model = genai.GenerativeModel(\"gemini-pro\")  # Load Gemini Model\n",
        "    prompt = f\"Given the phrase '{text}', provide the top 3 most likely word completions.\"\n",
        "\n",
        "    response = model.generate_content(prompt)\n",
        "    return response.text  # Extract the model's response\n"
      ],
      "metadata": {
        "id": "hZ1M3sG-wJyM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ðŸ”¹ Get user input\n",
        "user_text = input(\"Enter a phrase to auto-complete: \").strip()\n",
        "\n",
        "if user_text:\n",
        "    # ðŸ”¹ Predict using N-Gram Model\n",
        "    ngram_suggestions = auto_complete_ngram(user_text)\n",
        "\n",
        "    # ðŸ”¹ Predict using Gemini API\n",
        "    gemini_suggestions = auto_complete_gemini(user_text)\n",
        "\n",
        "    # ðŸ”¹ Print Suggestions\n",
        "    print(\"\\nðŸ”¹ Auto-Complete Suggestions (N-Gram Model):\", ngram_suggestions)\n",
        "    print(\"\\nðŸ”¹ Auto-Complete Suggestions (Gemini LLM):\", gemini_suggestions)\n",
        "else:\n",
        "    print(\"No input provided. Please enter a valid text.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        },
        "id": "NUHwcqBiwJ1M",
        "outputId": "4773a34e-1528-4b95-c1fc-2c5dc6c2eb29"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter a phrase to auto-complete:  televised interviews played a crucial role\n",
            "\n",
            "ðŸ”¹ Auto-Complete Suggestions (N-Gram Model): ['in']\n",
            "\n",
            "ðŸ”¹ Auto-Complete Suggestions (Gemini LLM): 1. in shaping public opinion\n",
            "2. in promoting political candidates\n",
            "3. in influencing voter turnout\n"
          ]
        }
      ]
    }
  ]
}